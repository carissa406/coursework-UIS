{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPC+m+hWY/BwO60S+CEQGp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carissa406/UIS/blob/main/Carissa_Hicks_assignment1_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Modifying the model in lab 3.2 to do Regression"
      ],
      "metadata": {
        "id": "RAE3x-Y_0ppc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u2QxeT_ceZ22"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(nx,nh,ny):\n",
        "    #set the random seed so the same random values are generated every time you run this function\n",
        "    np.random.seed(1)\n",
        "\n",
        "    #initialize weights to small random numbers and biases to zeros for each layer\n",
        "    W1=np.random.uniform(size=(nh,nx), low=-0.01, high=0.01)\n",
        "    b1=np.zeros((nh,1))\n",
        "    W2=np.random.uniform(size=(ny,nh), low=-0.01, high=0.01)\n",
        "    b2=np.zeros((ny,1))\n",
        "   \n",
        "    #create a dictionary of network parameters\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ],
      "metadata": {
        "id": "ijdAku1pRzm0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Forward Pass\n",
        "#relu activation\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)"
      ],
      "metadata": {
        "id": "tX82RbBEqLmE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(parameters,X):\n",
        "    Z1= np.dot(parameters[\"W1\"],X)+parameters[\"b1\"] # b1 is broadcasted n times before it is added to np.dpt(W1,X1)\n",
        "    A1=relu(Z1)\n",
        "    Z2=np.dot(parameters[\"W2\"],A1)+parameters[\"b2\"] #b2 is broadcasted n times before it is added to np.dpt(W2,A1)\n",
        "    Yhat=Z2 #sigmoid removed because regression doesnt use activation function, so Yhat is just Z2\n",
        "       \n",
        "    cache = {\"A1\": A1,\n",
        "             \"Z1\":Z1,\n",
        "             \"Z2\": Z2}\n",
        "    return Yhat,cache"
      ],
      "metadata": {
        "id": "LJ-L_o6UpUS5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using mean squared error for the loss function\n",
        "def compute_loss(Y,Yhat):\n",
        "    n=Y.shape[1]\n",
        "    loss = (1/n) + np.sum((Yhat - Y)**2)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "0eK5XInapWLJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Backward Pass\n",
        "#Gradient of Mean Squared Error loss function\n",
        "def dMSE (Y, Yhat):\n",
        "    return (Yhat - Y)\n",
        "\n",
        "#Derivative of Relu\n",
        "def drelu(Z):\n",
        "    drelu=np.where(Z>0, 1.0, 0.0) \n",
        "    return drelu "
      ],
      "metadata": {
        "id": "DY6ZAfp4pYCl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_pass(parameters, cache, X, Y, Yhat):\n",
        "    n=X.shape[1]\n",
        "\n",
        "    dZ2=dMSE(ùëå,Yhat )(cache[\"Z2\"])\n",
        "    dW2=(1/n)*np.dot(dZ2,cache[\"A1\"].T)\n",
        "    db2=(1/n)*np.sum(dZ2, axis=1, keepdims=True)\n",
        "    dA1=np.dot(parameters[\"W2\"].T,dZ2)\n",
        "    dZ1=dA1*drelu(cache[\"Z1\"])\n",
        "    dW1=(1/n)*np.dot(dZ1,X.T)\n",
        "    db1=(1/n)*np.sum(dZ1, axis=1, keepdims=True)\n",
        "    gradients={\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\":dW2,\n",
        "              \"db2\":db2\n",
        "              }\n",
        "    return gradients"
      ],
      "metadata": {
        "id": "m6NM1GD5pZ5V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, gradients, learning_rate):\n",
        "    parameters[\"W1\"]=parameters[\"W1\"]-learning_rate*gradients[\"dW1\"]\n",
        "    parameters[\"W2\"]=parameters[\"W2\"]-learning_rate*gradients[\"dW2\"]\n",
        "    parameters[\"b1\"]=parameters[\"b1\"]-learning_rate*gradients[\"db1\"]\n",
        "    parameters[\"b2\"]=parameters[\"b2\"]-learning_rate*gradients[\"db2\"]\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "14VOitoopbrd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_nn_model(train_X,train_Y,nh, val_X, val_Y, num_iterations, learning_rate):\n",
        "  \n",
        "    assert(train_X.shape[0]==val_X.shape[0]), \"train_X and val_X must have the same number of features\"\n",
        "    assert(train_X.shape[1]==train_Y.size), \"train_X and train_Y must have the same number of examples\"\n",
        "    assert(val_X.shape[1]==val_Y.size), \"val_X and val_Y must have the same number of examples\" \n",
        "    \n",
        "    \n",
        "    #getting the number of features\n",
        "    nx=train_X.shape[0]\n",
        "    \n",
        "    #one neuron in output layer with no activation function\n",
        "    ny=1\n",
        "    \n",
        "    # initializing the parameteres\n",
        "    parameters=initialize_parameters(nx,nh,ny)\n",
        "    \n",
        "    \n",
        "    #initialize lists to store the training and valideation losses for each iteration. \n",
        "    val_loss=[]\n",
        "    train_loss=[]\n",
        "    \n",
        "    #run num_iterations of gradient descent\n",
        "    for i in range (0, num_iterations):\n",
        "        #run the forward pass on train_X\n",
        "        Yhat_train, train_cache= forward_pass(parameters,train_X)\n",
        "        \n",
        "        #run the forward pass on val_X\n",
        "        Yhat_val,val_cache= forward_pass(parameters,val_X)\n",
        "        \n",
        "        #compute the loss on the train and val datasets\n",
        "        train_loss.append(compute_loss(train_Y,Yhat_train))\n",
        "        val_loss.append(compute_loss(val_Y,Yhat_val))\n",
        "\n",
        "        \"\"\"\n",
        "        run the backward pass. Note that the backward pass is only run on the training data not the validation data\n",
        "        Because the learning must be only done on the training data and hence, validation data is not used to update\n",
        "        the model parameters.  \n",
        "        \"\"\"\n",
        "        gradients=backward_pass(parameters, train_cache, train_X, train_Y,Yhat_train)\n",
        "        \n",
        "        # update the parameters\n",
        "        parameters=update_parameters(parameters, gradients, learning_rate)\n",
        "        \n",
        "        #print the trianing loss and validation loss for each iteration.\n",
        "        print(\"iteration {} :train_loss:{} val_loss{}\".format(i,train_loss[i],val_loss[i]))\n",
        "        \n",
        "    #create a dictionary history and put train_loss and validaiton_loss in it\n",
        "    history={\"val_loss\": val_loss,\n",
        "             \"train_loss\": train_loss}\n",
        "        \n",
        "        #return the parameters and the history\n",
        "    return parameters, history"
      ],
      "metadata": {
        "id": "kQVjS8thpgEv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get predictions\n",
        "def predict(parameters,X):\n",
        "    predicted_label=forward_pass(parameters, X)\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "S5_AIi_8pgo4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate accuracy\n",
        "def accuracy(observedY,predictedY):\n",
        "    #return the ratio of the examples for which predictedY=observedY over the total number of examples\n",
        "    return float(np.sum(predictedY==observedY))/observedY.size"
      ],
      "metadata": {
        "id": "Rgp6XL3LpjaZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Preparing California Housing Data"
      ],
      "metadata": {
        "id": "pHv1nzWE0w1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "df = pd.read_csv(\"sample_data/california_housing_train.csv\")"
      ],
      "metadata": {
        "id": "pKCEuBNdpkv9"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwKQAOMJ2ywJ",
        "outputId": "8db82ed0-f245-4bad-ceb0-eb8da355cf96"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17000, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "oM36ZH9yrIe4",
        "outputId": "5ecb07df-05fc-451b-b327-80d3058454f6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15c14495-414e-46d5-ad8b-d8c1c8d1cfd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15c14495-414e-46d5-ad8b-d8c1c8d1cfd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15c14495-414e-46d5-ad8b-d8c1c8d1cfd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15c14495-414e-46d5-ad8b-d8c1c8d1cfd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split training data into 80% training and 20% validation\n",
        "train = df.sample(frac=0.8, random_state=123)\n",
        "val = df.drop(train.index)"
      ],
      "metadata": {
        "id": "eEi_hOX6pmJb"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWZGpRwx3I2N",
        "outputId": "967f1f88-6272-4398-b03d-454064ccc7d7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13600, 9)\n",
            "(3400, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the input datasets train.csv and validation.csv and store them into numpy arrays\n",
        "train = train.to_numpy()\n",
        "test = pd.read_csv('sample_data/california_housing_test.csv').to_numpy()\n",
        "val = val.to_numpy()"
      ],
      "metadata": {
        "id": "ifJyJDcjrSyP"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ70kTgr6oWf",
        "outputId": "04d7106b-5dd0-4bb7-df7d-448d47be69e1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#separate the features from the target variable (median_house_value) in train, val and test\n",
        "train_X = train[:,:-1]\n",
        "train_Y = train[...,-1] #labels\n",
        "\n",
        "test_X = test[:,:-1]\n",
        "test_Y = test[...,-1] #labels\n",
        "\n",
        "val_X = val[:,:-1]\n",
        "val_Y = val[...,-1] #labels"
      ],
      "metadata": {
        "id": "K5bGPJK51F4f"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X.shape)\n",
        "print(test_X.shape)\n",
        "print(val_X.shape)\n",
        "print(train_Y.shape)\n",
        "print(test_Y.shape)\n",
        "print(val_Y.shape)\n",
        "print(test_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFxDKwjg5C7F",
        "outputId": "5104042c-f3eb-4902-a8bb-7347bb7f813c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13600, 8)\n",
            "(3000, 8)\n",
            "(3400, 8)\n",
            "(13600,)\n",
            "(3000,)\n",
            "(3400,)\n",
            "[344700. 176500. 270500. ...  62000. 162500. 500001.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the data: subtract mean of each feature and divide by the std, so that the feature is centered around 0 and has a unit std\n",
        "train_norm = (train_X - np.mean(train_X, axis=0))/np.std(train_X, axis=0)\n",
        "test_norm = (test_X - np.mean(train_X, axis=0))/np.std(train_X, axis=0)\n",
        "val_norm = (val_X - np.mean(train_X, axis=0))/np.std(train_X, axis=0)\n",
        "\n",
        "print(train_norm.shape)\n",
        "print(test_norm.shape)\n",
        "print(val_norm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiiqIpGH5g05",
        "outputId": "b192a3b0-a865-4a18-d0dd-cf8f8cadf9da"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13600, 8)\n",
            "(3000, 8)\n",
            "(3400, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#divide the median_house_values by 100k to scale them down\n",
        "train_norm = train_norm/100000\n",
        "test_norm = test_norm/100000\n",
        "val_norm = val_norm/100000"
      ],
      "metadata": {
        "id": "Ixk8jRfFxDN-"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transpose feature matricies for train,test,val and reshape target vectors to 2D arrays\n",
        "train_norm = train_norm.transpose()\n",
        "test_norm = test_norm.transpose()\n",
        "val_norm = val_norm.transpose()"
      ],
      "metadata": {
        "id": "KGtGca-BxSH3"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_Y=np.reshape(train_Y, (1, train_Y.size))\n",
        "test_Y=np.reshape(test_Y, (1, test_Y.size))\n",
        "val_Y=np.reshape(val_Y, (1, val_Y.size))"
      ],
      "metadata": {
        "id": "gydMq_Zm9Y0L"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_norm.shape)\n",
        "print(train_Y.shape)\n",
        "print(val_norm.shape)\n",
        "print(val_Y.shape)\n",
        "print(test_norm.shape)\n",
        "print(test_Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBhk8h3JzR4b",
        "outputId": "4c7cd73c-8320-4222-e3fd-8ab9e0d46f73"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 13600)\n",
            "(1, 13600)\n",
            "(8, 3400)\n",
            "(1, 3400)\n",
            "(8, 3000)\n",
            "(1, 3000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Training and hyper-parameter tuning"
      ],
      "metadata": {
        "id": "4JDbDt5T01vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterations=2000\n",
        "parameters, history=create_nn_model(train_norm,train_Y,50, val_norm, val_Y, iterations, 0.01)"
      ],
      "metadata": {
        "id": "jP2sDNDWpraT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "ca0260b1-b805-4bc1-9bba-8ffab85241c9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-a69032a7c372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_nn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-47c8f6022841>\u001b[0m in \u001b[0;36mcreate_nn_model\u001b[0;34m(train_X, train_Y, nh, val_X, val_Y, num_iterations, learning_rate)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mgradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYhat_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-f46b87709af1>\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(parameters, cache, X, Y, Yhat)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdZ2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mùëå\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYhat\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Z2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdW2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdb2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(0,iterations),history[\"train_loss\"],'b')\n",
        "plt.plot(range(0,iterations),history[\"val_loss\"],'r')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iterations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qosaCbnJps_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predicted_train=predict(parameters, train_X)\n",
        "predicted_val=predict(parameters, val_X)\n",
        "\n",
        "print(\"accurracy of the model on the training data is:\", accuracy(train_Y,predicted_train))\n",
        "print(\"accurracy of the model on the validation data is:\", accuracy(val_Y,predicted_val))"
      ],
      "metadata": {
        "id": "o1sPXugtpuZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}